// Se sacan los metodos de parseo fuera del pipeline 
def parseXml(String xmlContent) {
    def parsedXml = new XmlSlurper().parseText(xmlContent)
    // Se sacan las métricas directamente del elemento testsuites
    def testsuitesMetrics = [
        name: parsedXml.'@name'.text(),
        totalTests: parsedXml.'@tests'.text().toInteger(),
        totalFailures: parsedXml.'@failures'.text().toInteger(),
        totalErrors: parsedXml.'@errors'.text().toInteger(),
        totalTime: parsedXml.'@time'.text().toFloat()
    ]

    // Aquí por ahora asumimos que sólo hay un testsuite por testsuites, si hay más a futuro, se necesitará iterar
    def testsuiteMetrics = parsedXml.testsuite.collect {
        [
            name: it.'@name'.text(),
            tests: it.'@tests'.text().toInteger(),
            failures: it.'@failures'.text().toInteger(),
            errors: it.'@errors'.text().toInteger(),
            time: it.'@time'.text().toFloat(),
            skipped: it.'@skipped'.text().toInteger(),
            timestamp: it.'@timestamp'.text()
        ]
    }

    // Recopilación de las métricas de los testcase
    def testcaseMetrics = parsedXml.testsuite.testcase.collect { tc ->
        def tcMetrics = [
            name: tc.'@name'.text(),
            time: tc.'@time'.text().toFloat(),
            status: tc.'@status'.text()
        ]
        
        // Añadimos los campos adicionales basados en el estado
        switch (tc.'@status'.text()) {
            case 'PASSED':
                tcMetrics['result'] = 'OK'
                break
            case 'ERROR':
                tcMetrics['errorType'] = tc.error.'@type'.text()
                tcMetrics['errorMessage'] = tc.error.'@message'.text()
                break
            case 'FAILED':
                tcMetrics['failureType'] = tc.failure.'@type'.text()
                tcMetrics['failureMessage'] = tc.failure.'@message'.text()
                break
        }
        
        return tcMetrics
    }
    // Se retornan: testsuitesMetrics y testsuiteMetrics y testcaseMetrics
    return [testsuites: testsuitesMetrics, testsuite: testsuiteMetrics, testcase: testcaseMetrics]
}

//Metodo de preparación de datos para envío a prometheus
def constructPrometheusMetrics(Map metrics, String hash) {
    def metricData = ''
    def existingTestcases = [] // Almacena los nombres de los testcases para verificar duplicados

    // Métricas de testsuites
    def testsuitesValue = (metrics.testsuites.totalFailures > 0 || metrics.testsuites.totalErrors > 0) ? 1 : 0
    metricData += "katalon_testsuites_info{name=\"${metrics.testsuites.name}\", tests=\"${metrics.testsuites.totalTests}\", failures=\"${metrics.testsuites.totalFailures}\", errors=\"${metrics.testsuites.totalErrors}\", time=\"${metrics.testsuites.totalTime}\", identificador_ejecucion=\"${hash}\", timestamp_ejecucion=\"${env.PIPELINE_TIMESTAMP}\"} ${testsuitesValue}\n"

    // Métricas de testsuite
    metrics.testsuite.each { ts ->
        def testsuiteValue = (ts.failures > 0 || ts.errors > 0) ? 1 : 0
        metricData += "katalon_testsuite_info{name=\"${ts.name}\",tests=\"${ts.tests}\",failures=\"${ts.failures}\",errors=\"${ts.errors}\",time=\"${ts.time}\",skipped=\"${ts.skipped}\",timestamp=\"${ts.timestamp}\"} ${testsuiteValue}\n"
    }

    // Métricas de testcase con etiqueta de testsuite
    metrics.testsuite.each { ts ->
        metrics.testcase.each { tc ->
            def testcaseIdentifier = "${ts.name}_${tc.name}"
            if (!existingTestcases.contains(testcaseIdentifier)) {
                def testcaseValue = (tc.status == 'PASSED') ? 0 : 1
                metricData += "katalon_testcase_info{testsuite=\"${ts.name}\", name=\"${tc.name}\", time=\"${tc.time}\", status=\"${tc.status}\""
                
                if (testcaseValue == 0) {
                    metricData += ", result=\"OK\"} ${testcaseValue}\n"
                } else {
                    String detailType = tc.status == 'ERROR' ? 'error' : 'failure'
                    metricData += ", ${detailType}_type=\"${tc[detailType + 'Type']}\", ${detailType}_message=\"${tc[detailType + 'Message'].replaceAll('"', '\\"')}\"} ${testcaseValue}\n"
                }

                // Agregar el identificador del testcase a la lista de existentes
                existingTestcases << testcaseIdentifier
            }
        }
    }

    return metricData
}

def generateCustomHash() {
    def jobName = env.JOB_NAME ?: 'UnknownJob'
    def buildNumber = env.BUILD_NUMBER ?: '0'
    def currentTime = System.currentTimeMillis().toString()

    def stringToHash = "${jobName}-${buildNumber}-${currentTime}"
    def hash = stringToHash.hashCode().toString()

    return hash
}

pipeline {
    agent {
        kubernetes {
            defaultContainer 'jdk'
            yaml '''
apiVersion: v1
kind: Pod
spec:
  containers:
    - name: jdk
      image: docker.io/eclipse-temurin:20.0.1_9-jdk
      command:
        - cat
      tty: true
      volumeMounts:
        - name: m2-cache
          mountPath: /root/.m2
    - name: podman
      image: quay.io/containers/podman:v4.5.1
      command:
        - cat
      tty: true
      securityContext:
        runAsUser: 0
        privileged: true
    - name: kubectl
      image: docker.io/bitnami/kubectl:1.27.3
      command:
        - cat
      tty: true
      securityContext:
        runAsUser: 0
        privileged: true
  volumes:
    - name: m2-cache
      hostPath:
        path: /data/m2-cache
        type: DirectoryOrCreate
    - name: shared-data
      hostPath:
        path: /path/to/shared/folder
        type: DirectoryOrCreate
'''
        }
    }

    environment {
        // otras variables de entorno
        PIPELINE_TIMESTAMP = "${new Date().format('yyyy-MM-dd HH:mm:ss')}"
    }

        stages {

        stage('Generate Hash') {
            steps {
               script {
                     def jobName = env.JOB_NAME ?: 'UnknownJob'
                    def buildNumber = env.BUILD_NUMBER ?: '0'
                    def currentTime = System.currentTimeMillis().toString()

                    def stringToHash = "${jobName}-${buildNumber}-${currentTime}"
                    def hash = sh(script: "echo -n ${stringToHash} | sha256sum | cut -d' ' -f1", returnStdout: true).trim()
                    env.PIPELINE_HASH = hash
                }
            }
        }

          stage('List XML Reports') {
            steps {
                script {
                    // Lista el contenido del directorio xml_reports
                    sh 'ls -la xml_reports'
                }
            }
        }
       
        stage('Parse Katalon XML') {
            steps {
                script {
                    //Directorio de los xml
                    def xmlFiles = sh(script: "ls /home/jenkins/agent/workspace/seur/xml_reports/*.xml", returnStdout: true).trim().split('\n')
                    
                    def prometheusData = """
                        # HELP katalon_testsuites_info Test Suites Information
                        # TYPE katalon_testsuites_info gauge
                        # HELP katalon_testsuite_info Test Suite Information
                        # TYPE katalon_testsuite_info gauge
                        # HELP katalon_testcase_info Test Case Information
                        # TYPE katalon_testcase_info gauge
                        """

                    xmlFiles.eachWithIndex { filePath, index ->
                        def katalonXml = readFile(filePath)
                        def metrics = parseXml(katalonXml)

                        echo "Metrics parsed for ${filePath}: ${metrics}"

                        prometheusData += constructPrometheusMetrics(metrics, env.PIPELINE_HASH)

                        // Se agrega una traza para mostrar el nombre del archivo
                        echo "Processing file: ${filePath}"

                    }

                    writeFile(file: 'katalon.prom', text: prometheusData)
                    echo "Combined Prometheus data:\n${prometheusData}"
                }
            }
        }

        stage('Send to Prometheus') {
              steps {
                  script {
                    def prometheusData = readFile('katalon.prom').trim()
                    if (prometheusData) {
                        def pushgatewayUrl = "http://pushgateway-prometheus-pushgateway.default.svc.cluster.local:9091/metrics/job/katalon"
                        def response = sh(script: "curl -X POST --data-binary @katalon.prom ${pushgatewayUrl}", returnStdout: true).trim()
                        echo "Response from Pushgateway: ${response}"
                    } else {
                        error("Prometheus data está vacío, no envía al Pushgateway")
                    }
                  }
              }
          } 
    }
}